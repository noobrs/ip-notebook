{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12c45d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(988, 1500) (988, 1500) (988, 1500) (988, 1500)\n"
     ]
    }
   ],
   "source": [
    "import cv2, pywt\n",
    "import numpy as np\n",
    "\n",
    "# read image (grayscale for demo). For RGB, split channels and do this per channel.\n",
    "img = cv2.imread(\"images/lg-cat.webp\", cv2.IMREAD_GRAYSCALE).astype(np.float32)\n",
    "\n",
    "# 1-level 2D DWT with Haar (you can use 'db2', 'bior4.4', etc.)\n",
    "LL, (LH, HL, HH) = pywt.dwt2(img, wavelet='haar')\n",
    "\n",
    "print(LL.shape, LH.shape, HL.shape, HH.shape)  # each ~ (H//2, W//2)\n",
    "\n",
    "# reconstruct\n",
    "recon = pywt.idwt2((LL, (LH, HL, HH)), wavelet='haar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ff867a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[28.      28.      28.      ... 60.      60.      60.     ]\n",
      " [28.      28.      28.      ... 60.      60.      60.     ]\n",
      " [28.      28.      28.      ... 60.      60.      60.     ]\n",
      " ...\n",
      " [85.      85.      85.      ... 80.      80.      80.     ]\n",
      " [83.      83.      83.      ... 80.      80.      80.     ]\n",
      " [81.99999 81.99999 81.99999 ... 80.      80.      80.     ]]\n"
     ]
    }
   ],
   "source": [
    "print(LL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01321d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# level-2 decomposition\n",
    "coeffs = pywt.wavedec2(img, wavelet='haar', level=2)\n",
    "# coeffs[0] = LL at level 2\n",
    "# coeffs[1] = (LH2, HL2, HH2), coeffs[2] = (LH1, HL1, HH1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ea56cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 56.      ,  56.      ,  56.      , ..., 122.      , 120.      ,\n",
       "        120.      ],\n",
       "       [ 56.      ,  56.      ,  56.      , ..., 123.      , 120.      ,\n",
       "        120.      ],\n",
       "       [ 56.      ,  56.      ,  56.      , ..., 126.999985, 123.99999 ,\n",
       "        123.99999 ],\n",
       "       ...,\n",
       "       [179.99998 , 179.99998 , 179.      , ..., 153.99998 , 150.      ,\n",
       "        150.      ],\n",
       "       [172.99998 , 172.99998 , 172.99998 , ..., 161.99998 , 156.      ,\n",
       "        156.      ],\n",
       "       [164.99998 , 164.99998 , 164.99998 , ..., 163.99998 , 160.      ,\n",
       "        160.      ]], shape=(494, 750), dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LL2, (LH2, HL2, HH2) = coeffs[0], coeffs[1]\n",
    "LL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f6c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from typing import Union, Tuple\n",
    "\n",
    "def to_binary(\n",
    "    img: Union[str, np.ndarray],\n",
    "    size: Union[None, int, Tuple[int, int]] = None,   # int => square, tuple => (width, height)\n",
    "    method: str = \"otsu\",                             # \"otsu\" or \"fixed\"\n",
    "    threshold: int = None,                            # used when method=\"fixed\"\n",
    "    invert: bool = False                              # True => white background, black foreground\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert image to binary (0/255) with optional resize.\n",
    "\n",
    "    Returns: uint8 array of shape (H, W) with values {0, 255}.\n",
    "    \"\"\"\n",
    "    # 1) Load (if path) and ensure grayscale\n",
    "    if isinstance(img, str):\n",
    "        src = cv2.imread(img, cv2.IMREAD_UNCHANGED)\n",
    "        if src is None:\n",
    "            raise ValueError(f\"Could not read image: {img}\")\n",
    "    else:\n",
    "        src = img.copy()\n",
    "\n",
    "    if src.ndim == 3 and src.shape[2] == 4:       # drop alpha if present\n",
    "        src = cv2.cvtColor(src, cv2.COLOR_BGRA2BGR)\n",
    "    if src.ndim == 3:                             # assume BGR; OK for most OpenCV images\n",
    "        gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray = src\n",
    "\n",
    "    # 2) Resize if requested (OpenCV uses (width, height))\n",
    "    if size is not None:\n",
    "        if isinstance(size, int):\n",
    "            size = (size, size)\n",
    "        w, h = size\n",
    "        interp = cv2.INTER_AREA if (gray.shape[1] > w or gray.shape[0] > h) else cv2.INTER_LINEAR\n",
    "        gray = cv2.resize(gray, (w, h), interpolation=interp)\n",
    "\n",
    "    # 3) Make sure it's 8-bit for thresholding\n",
    "    if gray.dtype != np.uint8:\n",
    "        gray = cv2.normalize(gray, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)\n",
    "\n",
    "    # 4) Threshold\n",
    "    base_flag = cv2.THRESH_BINARY_INV if invert else cv2.THRESH_BINARY\n",
    "    if method.lower() == \"otsu\":\n",
    "        _, binary = cv2.threshold(gray, 0, 255, base_flag | cv2.THRESH_OTSU)\n",
    "    elif method.lower() == \"fixed\":\n",
    "        if threshold is None:\n",
    "            raise ValueError(\"Provide 'threshold' (0–255) when method='fixed'.\")\n",
    "        thr = int(np.clip(threshold, 0, 255))\n",
    "        _, binary = cv2.threshold(gray, thr, 255, base_flag)\n",
    "    else:\n",
    "        raise ValueError(\"method must be 'otsu' or 'fixed'.\")\n",
    "\n",
    "    return binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e45ac21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       ...,\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255],\n",
       "       [255, 255, 255, ..., 255, 255, 255]], shape=(256, 256), dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw1 = to_binary(\"images/f1-logo.png\", size=(256, 256), method=\"otsu\")\n",
    "bw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "297c13d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]], shape=(256, 256))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw1 = bw1/255\n",
    "\n",
    "bw1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6499993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Binary Image\", bw1)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fcab116a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bw2 = to_binary(\"images/f1-logo.png\", size=128, method=\"fixed\", threshold=127, invert=True)\n",
    "\n",
    "cv2.imshow(\"Binary Image\", bw2)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81210885",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def image_to_bitstream(\n",
    "    img,\n",
    "    size=None,\n",
    "    method=\"otsu\",\n",
    "    threshold=None,\n",
    "    invert=False,\n",
    "    pack=False,           # True -> return packed bytes\n",
    "    bitorder=\"big\"        # 'big' or 'little' for packbits\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns (bits, shape). If pack=True, 'bits' is uint8 bytes; else uint8 {0,1}.\n",
    "    'shape' is (H, W) of the binarized image for reconstruction later.\n",
    "    \"\"\"\n",
    "    bw = to_binary(img, size=size, method=method, threshold=threshold, invert=invert)\n",
    "    bits = (bw.ravel() // 255).astype(np.uint8)   # 255->1, 0->0\n",
    "\n",
    "    if pack:\n",
    "        return np.packbits(bits, bitorder=bitorder), bw.shape\n",
    "    else:\n",
    "        return bits, bw.shape\n",
    "\n",
    "def bitstream_to_image(\n",
    "    bits,\n",
    "    shape,\n",
    "    unpack=False,\n",
    "    bitorder=\"big\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Reconstruct a binary image from a bitstream and target shape.\n",
    "    If unpack=True, 'bits' is a bytes-like array packed by np.packbits.\n",
    "    \"\"\"\n",
    "    if unpack:\n",
    "        n = shape[0] * shape[1]\n",
    "        bits = np.unpackbits(bits, bitorder=bitorder)[:n]\n",
    "    img = (bits.reshape(shape).astype(np.uint8) * 255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d420311d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bits, shape = image_to_bitstream(\"images/f1-logo.png\", size=64, method=\"otsu\", pack=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2314f5aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], shape=(4096,), dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "00ba3953",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = bitstream_to_image(bits, shape, unpack=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59b11d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imshow(\"Binary Image\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3bfe0f",
   "metadata": {},
   "source": [
    "## Bitstream Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "442d2ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install cryptography\n",
    "import os, struct, numpy as np\n",
    "from typing import Literal\n",
    "from cryptography.hazmat.primitives.ciphers.aead import AESGCM, ChaCha20Poly1305\n",
    "from cryptography.hazmat.primitives.kdf.scrypt import Scrypt\n",
    "\n",
    "# ---- Parameters ----\n",
    "SCHEME_INFO = b\"wm:bits-aead-scrypt:v1\"    # domain separation (AAD)\n",
    "SALT_LEN   = 16\n",
    "NONCE_LEN  = 12\n",
    "KEY_LEN    = 32\n",
    "# Scrypt work factors (tune for your environment)\n",
    "SCRYPT_N   = 2**14\n",
    "SCRYPT_R   = 8\n",
    "SCRYPT_P   = 1\n",
    "\n",
    "def _kdf_scrypt(password: bytes, salt: bytes) -> bytes:\n",
    "    kdf = Scrypt(salt=salt, length=KEY_LEN, n=SCRYPT_N, r=SCRYPT_R, p=SCRYPT_P)\n",
    "    return kdf.derive(password)\n",
    "\n",
    "def _get_aead(alg: Literal[\"aesgcm\",\"chacha20poly1305\"], key: bytes):\n",
    "    if alg == \"aesgcm\":\n",
    "        return AESGCM(key), 1  # algo id 1\n",
    "    elif alg == \"chacha20poly1305\":\n",
    "        return ChaCha20Poly1305(key), 2  # algo id 2\n",
    "    else:\n",
    "        raise ValueError(\"alg must be 'aesgcm' or 'chacha20poly1305'.\")\n",
    "\n",
    "def encrypt_bitstream_with_password(\n",
    "    bits: np.ndarray,\n",
    "    password: str | bytes,\n",
    "    alg: Literal[\"aesgcm\",\"chacha20poly1305\"] = \"chacha20poly1305\",\n",
    "    bitorder: Literal[\"big\",\"little\"] = \"big\"\n",
    ") -> bytes:\n",
    "    \"\"\"\n",
    "    Encrypt a 0/1 uint8 bitstream with a password.\n",
    "    Returns a bytes 'package' containing header + salt + nonce + ciphertext(tag).\n",
    "    \"\"\"\n",
    "    if bits.dtype != np.uint8:\n",
    "        bits = bits.astype(np.uint8)\n",
    "    if not np.array_equal(bits, bits & 1):\n",
    "        raise ValueError(\"bits must be 0/1 uint8 array\")\n",
    "\n",
    "    # Pack bits -> bytes\n",
    "    bit_len = bits.size\n",
    "    pt = np.packbits(bits, bitorder=bitorder).tobytes()\n",
    "\n",
    "    # KDF\n",
    "    salt  = os.urandom(SALT_LEN)\n",
    "    key   = _kdf_scrypt(password if isinstance(password, bytes) else password.encode(), salt)\n",
    "\n",
    "    # AEAD\n",
    "    aead, alg_id = _get_aead(alg, key)\n",
    "    nonce = os.urandom(NONCE_LEN)\n",
    "    aad = SCHEME_INFO  # bind ciphertext to this context\n",
    "    ct = aead.encrypt(nonce, pt, aad)\n",
    "\n",
    "    # Package format:\n",
    "    # version(1) | alg_id(1) | bit_len(4, big-endian) | salt(16) | nonce(12) | ct(var)\n",
    "    header = b\"\\x01\" + bytes([alg_id]) + struct.pack(\">I\", bit_len) + salt + nonce\n",
    "    return header + ct\n",
    "\n",
    "def decrypt_bitstream_with_password(\n",
    "    package: bytes,\n",
    "    password: str | bytes,\n",
    "    bitorder: Literal[\"big\",\"little\"] = \"big\"\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Decrypt a package produced by encrypt_bitstream_with_password and return 0/1 bits.\n",
    "    \"\"\"\n",
    "    # Parse header\n",
    "    if len(package) < 1 + 1 + 4 + SALT_LEN + NONCE_LEN:\n",
    "        raise ValueError(\"package too short\")\n",
    "    off = 0\n",
    "    version = package[off]; off += 1\n",
    "    if version != 0x01:\n",
    "        raise ValueError(\"unsupported version\")\n",
    "    alg_id = package[off]; off += 1\n",
    "    bit_len = struct.unpack(\">I\", package[off:off+4])[0]; off += 4\n",
    "    salt = package[off:off+SALT_LEN]; off += SALT_LEN\n",
    "    nonce = package[off:off+NONCE_LEN]; off += NONCE_LEN\n",
    "    ct = package[off:]\n",
    "    if not ct:\n",
    "        raise ValueError(\"missing ciphertext\")\n",
    "\n",
    "    # Rebuild AEAD\n",
    "    key = _kdf_scrypt(password if isinstance(password, bytes) else password.encode(), salt)\n",
    "    alg = \"aesgcm\" if alg_id == 1 else \"chacha20poly1305\" if alg_id == 2 else None\n",
    "    if alg is None: raise ValueError(\"unknown alg_id\")\n",
    "    aead, _ = _get_aead(alg, key)\n",
    "\n",
    "    pt = aead.decrypt(nonce, ct, SCHEME_INFO)\n",
    "\n",
    "    # Unpack bytes -> bits and trim to exact bit_len\n",
    "    unpacked = np.unpackbits(np.frombuffer(pt, dtype=np.uint8), bitorder=bitorder)\n",
    "    return unpacked[:bit_len].astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4ffb5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From earlier:\n",
    "# bits, shape = image_to_bitstream(\"logo.png\", size=64, method=\"otsu\", pack=False)\n",
    "\n",
    "password = \"My$trongPa55\"\n",
    "package = encrypt_bitstream_with_password(bits, password, alg=\"chacha20poly1305\")\n",
    "# If your embedding layer requires bits, convert package bytes -> bits:\n",
    "pkg_bits = np.unpackbits(np.frombuffer(package, dtype=np.uint8), bitorder=\"big\")\n",
    "\n",
    "# ...embed pkg_bits into your watermark...\n",
    "# On extraction, recover pkg_bits (in original order), then:\n",
    "package_bytes = np.packbits(pkg_bits, bitorder=\"big\").tobytes()\n",
    "rec_bits = decrypt_bitstream_with_password(package_bytes, \"My$trongPa55\")\n",
    "\n",
    "# rec_bits == bits (0/1), ready for bitstream_to_image(rec_bits, shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d99503a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4496,), (4096,), (4096,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkg_bits.shape, bits.shape, rec_bits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44e9537f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package as bytes: [  1   2   0   0  16   0  18 237 204 151  10 115 154 253  35 209 192  52\n",
      " 205 102 206 238 123 195  44 111  11  30 239  81  36 239  38 220  54   0\n",
      " 205 172  46  95 111 235  49   7  75 230 105  43 228  84  46 205  39 183\n",
      " 102 201   9  13 183 135 178  12  68  21 188  27 246 164 218  24 192  47\n",
      "  44 248  47 255  65 140 115  24  28  15  37  16 152 133 126 129 230  55\n",
      "  66 219 127  76 138  35 117  92 122   0  16 232  22  34 251 202  81  17\n",
      " 132 140  85 238 117   2 232  83  32  12 104 237  28 215 144 182 178 174\n",
      " 223 234   5  46  69  73 167 213 175  36 172 118 161  97  77 236 139   4\n",
      " 188 114  73  80 180  55  18  76 241 122 170 212  91  38 119  59  74  77\n",
      " 218 146  49 161 109  94 219 129 133 106 222 210 252 140 113  27 195 169\n",
      " 101   4 215  61 230 142 227 224 153  39 109 212 254 205  28 164 191   6\n",
      " 247 107 171 176  79 190 174  39 128 238 245 104  41  51  25 255  28 152\n",
      "  80  33 223  56 185 174  53 226 185   0 108  44 123 231 182 240  56 182\n",
      "  91  62  44 128  72  82  76 189  31 143  41  60  32 145  63 118  13 248\n",
      "  54 155  19 238  56 230 187  45  58 113 246 211 171 193 220 112  61  63\n",
      "  57 203 169  68 158 244 158 104  88 136  99 175 185 128 246 152 250 221\n",
      " 219  82 121  71 208  87 167 101 173  97 140 235 134  43  17 200 153  42\n",
      " 118 109 107 166 182 101 164   7 182 170  73   4  68 218 177  93  82  70\n",
      " 109  29 131  98  98 135 114  29 138 143 116 241 191  73 248  77 135 238\n",
      " 221  28 176 196 107 162 110  67 246  98  72 210 133 100  91  24  77 222\n",
      " 183 106  71 254 119 198 242 185 225  56  57 216 195  61  70 211  15 154\n",
      "  39 161  83 113 151  57 126 183  33 128 227 114  12  74 118 171  86   8\n",
      " 245 164  70   7  53 114  42   7 242  70  29 237 163  78  79 251  60 190\n",
      "  20 171  47 205  64 141 161 152  54 189  27 205  99 134 152  89  51 205\n",
      " 224 191 254  45  43 231   1 210 105 112 248 167 100  70  96  95   9  64\n",
      " 115  15 194 255 215  54  88 108 233 168  63  88 174 212  82 223  40 129\n",
      "  33  50  71  33  76  87 114 191 174 252  90 187  22 183 160  89  58 254\n",
      " 164  81 121  50 236 252 212 223  59  25  62  24   2 114  18 167 223 104\n",
      "  24 133 134 214  55  29 236  59  79 154 125  47 162 218 173  42 108 246\n",
      "  14  95 117 195 177  51 205   3  81  40  24  45  90 215  71 127 217  20\n",
      "  40 127 148  31 100 157 124  37  67 132 189 202   9 198 165 126  60  90\n",
      " 224  69 216 225]\n",
      "Package as hex: 01020000100012edcc970a739afd23d1c034cd66ceee7bc32c6f0b1eef5124ef26dc3600cdac2e5f6feb31074be6692be4542ecd27b766c9090db787b20c4415bc1bf6a4da18c02f2cf82fff418c73181c0f251098857e81e63742db7f4c8a23755c7a0010e81622fbca5111848c55ee7502e853200c68ed1cd790b6b2aedfea052e4549a7d5af24ac76a1614dec8b04bc724950b437124cf17aaad45b26773b4a4dda9231a16d5edb81856aded2fc8c711bc3a96504d73de68ee3e099276dd4fecd1ca4bf06f76babb04fbeae2780eef568293319ff1c985021df38b9ae35e2b9006c2c7be7b6f038b65b3e2c8048524cbd1f8f293c20913f760df8369b13ee38e6bb2d3a71f6d3abc1dc703d3f39cba9449ef49e68588863afb980f698fadddb527947d057a765ad618ceb862b11c8992a766d6ba6b665a407b6aa490444dab15d52466d1d83626287721d8a8f74f1bf49f84d87eedd1cb0c46ba26e43f66248d285645b184ddeb76a47fe77c6f2b9e13839d8c33d46d30f9a27a1537197397eb72180e3720c4a76ab5608f5a4460735722a07f2461deda34e4ffb3cbe14ab2fcd408da19836bd1bcd6386985933cde0bffe2d2be701d26970f8a76446605f0940730fc2ffd736586ce9a83f58aed452df2881213247214c5772bfaefc5abb16b7a0593afea4517932ecfcd4df3b193e18027212a7df68188586d6371dec3b4f9a7d2fa2daad2a6cf60e5f75c3b133cd035128182d5ad7477fd914287f941f649d7c254384bdca09c6a57e3c5ae045d8e1\n",
      "Size: 562 bytes\n"
     ]
    }
   ],
   "source": [
    "# For your large encrypted package, convert to bytes instead\n",
    "def binary_to_bytes(bits, bitorder=\"big\"):\n",
    "    \"\"\"Convert binary array to bytes\"\"\"\n",
    "    return np.packbits(bits, bitorder=bitorder)\n",
    "\n",
    "def bytes_to_hex(byte_array):\n",
    "    \"\"\"Convert bytes to hex string for display\"\"\"\n",
    "    return byte_array.tobytes().hex()\n",
    "\n",
    "# Convert your large binary to bytes\n",
    "pkg_bytes = binary_to_bytes(pkg_bits)\n",
    "print(f\"Package as bytes: {pkg_bytes}\")\n",
    "print(f\"Package as hex: {bytes_to_hex(pkg_bytes)}\")\n",
    "print(f\"Size: {len(pkg_bytes)} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2520569d",
   "metadata": {},
   "source": [
    "encryption module\n",
    "\n",
    "now need to check if it my watermarking need this encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d590ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 44.3762 dB\n",
      "PSNR: 36.4849 dB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pywt\n",
    "import cv2\n",
    "\n",
    "# ---------------------------\n",
    "# Utility: PSNR (optional)\n",
    "# ---------------------------\n",
    "def psnr(img_a: np.ndarray, img_b: np.ndarray) -> float:\n",
    "    a = img_a.astype(np.float64)\n",
    "    b = img_b.astype(np.float64)\n",
    "    mse = np.mean((a - b) ** 2)\n",
    "    if mse <= 1e-12:\n",
    "        return 100.0\n",
    "    return 20.0 * np.log10(255.0 / np.sqrt(mse))\n",
    "\n",
    "# ---------------------------\n",
    "# YCbCr I/O helpers\n",
    "# ---------------------------\n",
    "def rgb_to_ycbcr_arrays(pil_img: Image.Image):\n",
    "    im = pil_img.convert(\"RGB\")\n",
    "    ycbcr = im.convert(\"YCbCr\")\n",
    "    Y  = np.array(ycbcr.getchannel(0), dtype=np.float64)\n",
    "    Cb = np.array(ycbcr.getchannel(1), dtype=np.uint8)\n",
    "    Cr = np.array(ycbcr.getchannel(2), dtype=np.uint8)\n",
    "    return Y, Cb, Cr\n",
    "\n",
    "def merge_ycbcr_to_rgb(Y: np.ndarray, Cb: np.ndarray, Cr: np.ndarray) -> Image.Image:\n",
    "    Y8 = np.rint(np.clip(Y, 0, 255)).astype(np.uint8)\n",
    "    ycbcr = Image.merge(\n",
    "        \"YCbCr\",\n",
    "        (Image.fromarray(Y8), Image.fromarray(Cb), Image.fromarray(Cr))\n",
    "    )\n",
    "    return ycbcr.convert(\"RGB\")\n",
    "\n",
    "# ---------------------------\n",
    "# Watermark (32x32) -> bits\n",
    "# ---------------------------\n",
    "def wm32_to_bits(wm_img: Image.Image, threshold: int = 127) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert a mono 32x32 image to a 1024-length bit vector (row-major).\n",
    "    Any pixel > threshold -> 1; else 0.\n",
    "    \"\"\"\n",
    "    g = wm_img.convert(\"L\").resize((32, 32), Image.NEAREST)\n",
    "    arr = np.array(g, dtype=np.uint8)\n",
    "    bits = (arr > threshold).astype(np.uint8).ravel()\n",
    "    if bits.size != 1024:\n",
    "        raise ValueError(\"Watermark must resolve to exactly 32x32 = 1024 bits.\")\n",
    "    return bits\n",
    "\n",
    "# ---------------------------\n",
    "# DWT4: get/set LH4 (periodization)\n",
    "# ---------------------------\n",
    "def dwt4_get_LH4(Y: np.ndarray, wavelet='haar'):\n",
    "    coeffs = pywt.wavedec2(Y, wavelet=wavelet, level=4, mode='periodization')\n",
    "    # coeffs: [LL4, (LH4,HL4,HH4), (LH3,...), (LH2,...), (LH1,...)]\n",
    "    LH4, HL4, HH4 = coeffs[1]\n",
    "    return coeffs, LH4\n",
    "\n",
    "def dwt4_set_LH4_and_recon(coeffs, LH4_new: np.ndarray, wavelet='haar') -> np.ndarray:\n",
    "    # replace only LH4, keep HL4/HH4 as-is\n",
    "    LH4, HL4, HH4 = coeffs[1]\n",
    "    coeffs[1] = (LH4_new, HL4, HH4)\n",
    "    Yw = pywt.waverec2(coeffs, wavelet=wavelet, mode='periodization')\n",
    "    return Yw\n",
    "\n",
    "# ---------------------------\n",
    "# QIM on magnitude (sign-preserving)\n",
    "# ---------------------------\n",
    "def qim_embed_mag(c: float, b: int, Delta: float) -> float:\n",
    "    s = -1.0 if c < 0 else 1.0\n",
    "    m = abs(c)\n",
    "    q = np.floor(m / Delta)\n",
    "    m2 = (q + (0.25 if b == 0 else 0.75)) * Delta\n",
    "    return s * m2\n",
    "\n",
    "def qim_llr_mag(c: float, Delta: float) -> float:\n",
    "    m = abs(c); x = m / Delta\n",
    "    f = x - np.floor(x)\n",
    "    return abs(f - 0.25) - abs(f - 0.75)  # <0 => bit 0 closer, >0 => bit 1 closer\n",
    "\n",
    "# ---------------------------\n",
    "# EMBED: LH4 first 64x64, 4 repeats\n",
    "# ---------------------------\n",
    "def embed_lh4_fixed64(\n",
    "    host_img: Image.Image,\n",
    "    wm32: Image.Image,\n",
    "    alpha: float = 0.8,\n",
    "    wavelet: str = 'haar'\n",
    ") -> Image.Image:\n",
    "    \"\"\"\n",
    "    Embed a 32x32 mono watermark (as bits) into the first 64x64 of LH4.\n",
    "    Each bit is embedded 4 times (since 64*64=4096 = 1024*4).\n",
    "\n",
    "    host must be >= 512x512 (any rectangular size OK).\n",
    "    If LH4 is larger than 64x64 (e.g., 64x75), we only use [:64, :64].\n",
    "    \"\"\"\n",
    "    # Convert host to YCbCr arrays\n",
    "    Y, Cb, Cr = rgb_to_ycbcr_arrays(host_img)\n",
    "    H, W = Y.shape\n",
    "\n",
    "    # Sanity: host size\n",
    "    if H < 512 or W < 512:\n",
    "        raise ValueError(f\"Host image too small ({H}x{W}); need at least 512x512.\")\n",
    "\n",
    "    # DWT level-4 and get LH4\n",
    "    coeffs, LH4 = dwt4_get_LH4(Y, wavelet=wavelet)\n",
    "    h4, w4 = LH4.shape\n",
    "    if h4 < 64 or w4 < 64:\n",
    "        raise ValueError(f\"LH4 too small ({h4}x{w4}); need at least 64x64.\")\n",
    "\n",
    "    # Only use the first 64x64 region for embedding\n",
    "    region = LH4[:64, :64].astype(np.float64).copy()\n",
    "\n",
    "    # Δ from median magnitude in the region (robust scaling)\n",
    "    med = np.median(np.abs(region))\n",
    "    Delta = alpha * (med if med > 0 else 1.0)\n",
    "\n",
    "    # Watermark -> bits and repeat 4x to fill 4096 coeffs exactly\n",
    "    bits = wm32_to_bits(wm32)                    # length 1024\n",
    "    R = 4\n",
    "    if 64*64 != bits.size * R:\n",
    "        raise RuntimeError(\"Internal size mismatch; 64*64 must equal 1024*4.\")\n",
    "    # Embed in raster order\n",
    "    flat = region.ravel()\n",
    "    for k in range(flat.size):                   # 0..4095\n",
    "        b = int(bits[k % bits.size])             # repeat 4x\n",
    "        flat[k] = qim_embed_mag(flat[k], b, Delta)\n",
    "    region_e = flat.reshape(region.shape)\n",
    "\n",
    "    # Put region back and reconstruct\n",
    "    LH4_new = LH4.copy().astype(np.float64)\n",
    "    LH4_new[:64, :64] = region_e\n",
    "    Yw = dwt4_set_LH4_and_recon(coeffs, LH4_new, wavelet=wavelet)\n",
    "\n",
    "    # Merge back to RGB\n",
    "    out = merge_ycbcr_to_rgb(Yw, Cb, Cr)\n",
    "    return out\n",
    "\n",
    "def save_jpeg(input_path: str, out_path: str, quality: int = 75):\n",
    "    Image.open(input_path).convert(\"RGB\").save(out_path, quality=quality, subsampling=0, optimize=False)\n",
    "\n",
    "# ---------------------------\n",
    "# EXTRACT: mirror the same mapping\n",
    "# ---------------------------\n",
    "def extract_lh4_fixed64(\n",
    "    wm_host_img: Image.Image,\n",
    "    wavelet: str = 'haar',\n",
    "    alpha: float = 0.8\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Blind extract 32x32 bits from LH4 first 64x64 (assumes 4 repeats).\n",
    "    Returns an array shape (32, 32) with values {0,1}.\n",
    "    \"\"\"\n",
    "    Y, _, _ = rgb_to_ycbcr_arrays(wm_host_img)\n",
    "    coeffs, LH4 = dwt4_get_LH4(Y, wavelet=wavelet)\n",
    "    h4, w4 = LH4.shape\n",
    "    if h4 < 64 or w4 < 64:\n",
    "        raise ValueError(f\"LH4 too small ({h4}x{w4}); need at least 64x64.\")\n",
    "\n",
    "    region = LH4[:64, :64].astype(np.float64)\n",
    "    # Recompute Δ from current region (blind)\n",
    "    med = np.median(np.abs(region))\n",
    "    Delta = alpha * (med if med > 0 else 1.0)\n",
    "\n",
    "    flat = region.ravel()\n",
    "    R = 4\n",
    "    n_bits = 1024\n",
    "    scores = np.zeros(n_bits, dtype=np.float64)\n",
    "\n",
    "    # For bit i, its 4 positions are at indices:\n",
    "    # i, i+1024, i+2048, i+3072  (since we wrote in raster)\n",
    "    for i in range(n_bits):\n",
    "        s = 0.0\n",
    "        for r in range(R):\n",
    "            k = i + r * n_bits\n",
    "            s += qim_llr_mag(flat[k], Delta)\n",
    "        scores[i] = s\n",
    "\n",
    "    bits = (scores > 0).astype(np.uint8).reshape(32, 32)\n",
    "    return bits\n",
    "\n",
    "# ---------------------------\n",
    "# Example usage (uncomment to run)\n",
    "# ---------------------------\n",
    "HOST_IMAGE_PATH = \"images/cat.webp\"\n",
    "WATERMARK_IMAGE_PATH = \"images/s.jpg\"\n",
    "OUTPUT_WATERMARK_PATH = \"my-experiment/wm_recovered.png\"\n",
    "OUTPUT_WATERMARKED_PATH = \"my-experiment/host_marked.png\"\n",
    "\n",
    "OUTPUT_JPEG_WATERMARK_PATH = \"my-experiment/wm_recovered_compressed.jpg\"\n",
    "OUTPUT_JPEG_WATERMARKED_PATH = \"my-experiment/host_marked_compressed.jpg\"\n",
    "\n",
    "host = Image.open(HOST_IMAGE_PATH)\n",
    "wm   = Image.open(WATERMARK_IMAGE_PATH)  # mono logo/pattern\n",
    "watermarked = embed_lh4_fixed64(host, wm, alpha=1.0, wavelet='haar')\n",
    "watermarked.save(OUTPUT_WATERMARKED_PATH)\n",
    "\n",
    "recovered_bits = extract_lh4_fixed64(watermarked, wavelet='haar', alpha=1.0)\n",
    "# If you want a viewable 0/255 image:\n",
    "rec_img = Image.fromarray((recovered_bits*255).astype(np.uint8))\n",
    "rec_img.save(OUTPUT_WATERMARK_PATH)\n",
    "\n",
    "psnr_value = psnr(cv2.imread(HOST_IMAGE_PATH), cv2.imread(OUTPUT_WATERMARKED_PATH))\n",
    "print(f\"PSNR: {psnr_value:.4f} dB\")\n",
    "\n",
    "# JPEG Attacks\n",
    "jpeg_watermarked = Image.open(OUTPUT_JPEG_WATERMARKED_PATH)\n",
    "save_jpeg(OUTPUT_WATERMARKED_PATH, OUTPUT_JPEG_WATERMARKED_PATH, quality=75)\n",
    "recovered_bits = extract_lh4_fixed64(jpeg_watermarked, wavelet='haar', alpha=1.0)\n",
    "# If you want a viewable 0/255 image:\n",
    "rec_img = Image.fromarray((recovered_bits*255).astype(np.uint8))\n",
    "rec_img.save(OUTPUT_JPEG_WATERMARK_PATH)\n",
    "\n",
    "psnr_value = psnr(cv2.imread(HOST_IMAGE_PATH), cv2.imread(OUTPUT_JPEG_WATERMARKED_PATH))\n",
    "print(f\"PSNR: {psnr_value:.4f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70bb513",
   "metadata": {},
   "source": [
    "# Grok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e36e9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter, maximum_filter, gaussian_laplace\n",
    "from scipy.signal import wiener\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "def harris_corner(image, sigma=1.0, k=0.05):\n",
    "    Iy, Ix = np.gradient(image)\n",
    "    Ix2 = gaussian_filter(Ix**2, sigma)\n",
    "    Iy2 = gaussian_filter(Iy**2, sigma)\n",
    "    Ixy = gaussian_filter(Ix*Iy, sigma)\n",
    "    det = Ix2 * Iy2 - Ixy**2\n",
    "    trace = Ix2 + Iy2\n",
    "    r = det - k * trace**2\n",
    "    return r\n",
    "\n",
    "def get_feature_points(image, num_octaves=4, th=0.01):\n",
    "    points = []\n",
    "    current_image = image.astype(float).copy()\n",
    "    for octave in range(num_octaves):\n",
    "        sigma = 1.6 * (2 ** octave)\n",
    "        r = harris_corner(current_image, sigma=sigma)\n",
    "        local_max = maximum_filter(r, size=3) == r\n",
    "        coords = np.nonzero(local_max & (r > th))\n",
    "        for y, x in zip(*coords):\n",
    "            lap = np.abs(gaussian_laplace(current_image, sigma))[y, x] * sigma**2\n",
    "            lap_prev = np.abs(gaussian_laplace(current_image, sigma / 1.2))[y, x] * (sigma / 1.2)**2 if sigma > 1.6 else 0\n",
    "            lap_next = np.abs(gaussian_laplace(current_image, sigma * 1.2))[y, x] * (sigma * 1.2)**2\n",
    "            if lap > lap_prev and lap > lap_next:\n",
    "                points.append((y * (2 ** octave), x * (2 ** octave), lap))\n",
    "    # Sort by response (lap), take top 50\n",
    "    points = sorted(points, key=lambda p: p[2], reverse=True)[:50]\n",
    "    return np.array([p[:2] for p in points])\n",
    "\n",
    "def barycentric_coords(tri, p):\n",
    "    T = np.array([[tri[0,0] - tri[2,0], tri[1,0] - tri[2,0]],\n",
    "                  [tri[0,1] - tri[2,1], tri[1,1] - tri[2,1]]])\n",
    "    diff = p - tri[2]\n",
    "    ab = np.linalg.solve(T, diff)\n",
    "    g = 1 - ab[0] - ab[1]\n",
    "    return np.array([ab[0], ab[1], g])\n",
    "\n",
    "def compute_nvf(image):\n",
    "    mean = gaussian_filter(image, 1.0)\n",
    "    mean_sq = gaussian_filter(image**2, 1.0)\n",
    "    variance = mean_sq - mean**2\n",
    "    variance_max = variance.max() + 1e-9  # avoid division by zero\n",
    "    nvf = variance / variance_max\n",
    "    return nvf\n",
    "\n",
    "def embed_watermark(image, watermark, alpha=0.2, beta=0.05, r=0.01):\n",
    "    h, w = image.shape\n",
    "    D = r * (w + h)\n",
    "    points = get_feature_points(image)\n",
    "    selected = []\n",
    "    for p in points:\n",
    "        if all(np.linalg.norm(p - q) > D for q in selected):\n",
    "            selected.append(p)\n",
    "    points = np.array(selected)\n",
    "    if len(points) < 3:\n",
    "        raise ValueError(\"Not enough feature points for watermarking.\")\n",
    "    delau = Delaunay(points)\n",
    "    simplices = delau.simplices\n",
    "    pts = delau.points\n",
    "    watermarked = image.copy().astype(float)\n",
    "    nvf = compute_nvf(image)\n",
    "    for tri_idx in simplices:\n",
    "        target_tri = pts[tri_idx]\n",
    "        standard_tri = np.array([[0,0], [32,0], [0,32]], dtype=float)\n",
    "        X = np.zeros((6,6))\n",
    "        y = np.zeros(6)\n",
    "        for i in range(3):\n",
    "            x1, y1 = standard_tri[i]\n",
    "            X[2*i, 0] = x1\n",
    "            X[2*i, 1] = y1\n",
    "            X[2*i, 2] = 1\n",
    "            X[2*i+1, 3] = x1\n",
    "            X[2*i+1, 4] = y1\n",
    "            X[2*i+1, 5] = 1\n",
    "            y[2*i] = target_tri[i,0]\n",
    "            y[2*i+1] = target_tri[i,1]\n",
    "        params = np.linalg.solve(X, y)\n",
    "        a11, a12, b1, a21, a22, b2 = params\n",
    "        A = np.array([[a11, a12, b1], [a21, a22, b2], [0,0,1]])\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        min_x = int(np.min(target_tri[:,0]))\n",
    "        max_x = int(np.max(target_tri[:,0])) + 1\n",
    "        min_y = int(np.min(target_tri[:,1]))\n",
    "        max_y = int(np.max(target_tri[:,1])) + 1\n",
    "        for yy in range(max(min_y, 0), min(max_y, h)):\n",
    "            for xx in range(max(min_x, 0), min(max_x, w)):\n",
    "                p = np.array([xx, yy])\n",
    "                bary = barycentric_coords(target_tri, p)\n",
    "                if np.all(bary >= 0) and np.sum(bary) <= 1 + 1e-6:\n",
    "                    p_hom = np.array([xx, yy, 1])\n",
    "                    std_hom = A_inv @ p_hom\n",
    "                    std_x = std_hom[0] / std_hom[2]\n",
    "                    std_y = std_hom[1] / std_hom[2]\n",
    "                    if 0 <= std_x < 32 and 0 <= std_y < 32:\n",
    "                        wc = watermark[int(std_y), int(std_x)]\n",
    "                        lam = alpha * (1 - nvf[yy, xx]) + beta * nvf[yy, xx]\n",
    "                        watermarked[yy, xx] += lam * wc\n",
    "    return np.clip(watermarked, 0, 255).astype(np.uint8) if image.dtype == np.uint8 else watermarked\n",
    "\n",
    "def extract_watermark(image, watermark_size=32, alpha=0.2, beta=0.05, r=0.01):\n",
    "    h, w = image.shape\n",
    "    D = r * (w + h)\n",
    "    points = get_feature_points(image.astype(float))\n",
    "    selected = []\n",
    "    for p in points:\n",
    "        if all(np.linalg.norm(p - q) > D for q in selected):\n",
    "            selected.append(p)\n",
    "    points = np.array(selected)\n",
    "    if len(points) < 3:\n",
    "        return np.zeros((watermark_size, watermark_size))\n",
    "    delau = Delaunay(points)\n",
    "    simplices = delau.simplices\n",
    "    pts = delau.points\n",
    "    denoised = wiener(image.astype(float), mysize=(5,5))\n",
    "    noise = image.astype(float) - denoised\n",
    "    extracted = []\n",
    "    for tri_idx in simplices:\n",
    "        target_tri = pts[tri_idx]\n",
    "        standard_tri = np.array([[0,0], [32,0], [0,32]], dtype=float)\n",
    "        X = np.zeros((6,6))\n",
    "        y = np.zeros(6)\n",
    "        for i in range(3):\n",
    "            x1, y1 = standard_tri[i]\n",
    "            X[2*i, 0] = x1\n",
    "            X[2*i, 1] = y1\n",
    "            X[2*i, 2] = 1\n",
    "            X[2*i+1, 3] = x1\n",
    "            X[2*i+1, 4] = y1\n",
    "            X[2*i+1, 5] = 1\n",
    "            y[2*i] = target_tri[i,0]\n",
    "            y[2*i+1] = target_tri[i,1]\n",
    "        params = np.linalg.solve(X, y)\n",
    "        a11, a12, b1, a21, a22, b2 = params\n",
    "        A = np.array([[a11, a12, b1], [a21, a22, b2], [0,0,1]])\n",
    "        A_inv = np.linalg.inv(A)\n",
    "        wm_extract = np.zeros((watermark_size, watermark_size))\n",
    "        for sy in range(watermark_size):\n",
    "            for sx in range(watermark_size):\n",
    "                p_std = np.array([sx, sy, 1])\n",
    "                p_target = A @ p_std\n",
    "                x_t = p_target[0] / p_target[2]\n",
    "                y_t = p_target[1] / p_target[2]\n",
    "                bary = barycentric_coords(target_tri, np.array([x_t, y_t]))\n",
    "                if np.all(bary >= 0) and np.sum(bary) <= 1 + 1e-6:\n",
    "                    xt = int(round(x_t))\n",
    "                    yt = int(round(y_t))\n",
    "                    if 0 <= xt < w and 0 <= yt < h:\n",
    "                        wm_extract[sy, sx] = noise[yt, xt]\n",
    "        extracted.append(wm_extract)\n",
    "    if len(extracted) > 0:\n",
    "        avg_wm = np.mean(extracted, axis=0)\n",
    "    else:\n",
    "        avg_wm = np.zeros((watermark_size, watermark_size))\n",
    "    return avg_wm\n",
    "\n",
    "# Example usage (commented out, as it requires an image)\n",
    "# np.random.seed(42)\n",
    "# watermark = 2 * (np.random.rand(32, 32) > 0.5) - 1  # Fixed monochrome watermark (+1 or -1)\n",
    "# # Assume 'host_image' is a numpy array (grayscale)\n",
    "# watermarked_image = embed_watermark(host_image, watermark)\n",
    "# # Apply attacks (resize, rotation)\n",
    "# from scipy.ndimage import zoom, rotate\n",
    "# attacked = zoom(watermarked_image, 0.8)  # resize\n",
    "# attacked = rotate(attacked, 30)  # rotation\n",
    "# extracted_wm = extract_watermark(attacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50dd1973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing images...\n",
      "Host image shape: (980, 980)\n",
      "Watermark shape: (32, 32)\n",
      "\n",
      "Embedding watermark...\n",
      "PSNR (Host vs Watermarked): 62.81 dB\n",
      "\n",
      "Testing extraction without attacks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ip-notebook\\venv\\lib\\site-packages\\scipy\\signal\\_signaltools.py:1673: RuntimeWarning: divide by zero encountered in divide\n",
      "  res *= (1 - noise / lVar)\n",
      "d:\\ip-notebook\\venv\\lib\\site-packages\\scipy\\signal\\_signaltools.py:1673: RuntimeWarning: invalid value encountered in multiply\n",
      "  res *= (1 - noise / lVar)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BER (No attack): 0.6641 (66.41%)\n",
      "\n",
      "Testing robustness against attacks:\n",
      "--------------------------------------------------\n",
      "Rotation 5°         : BER = 0.6699 (66.99%), PSNR =   6.51 dB\n",
      "Rotation 10°        : BER = 0.6592 (65.92%), PSNR =   5.69 dB\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 272\u001b[0m\n\u001b[0;32m    267\u001b[0m     watermark \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m watermark \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m  \u001b[38;5;66;03m# Convert to +1/-1\u001b[39;00m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m host, watermark\n\u001b[1;32m--> 272\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    274\u001b[0m host, watermark \u001b[38;5;241m=\u001b[39m generate_test_images()\n\u001b[0;32m    276\u001b[0m \u001b[38;5;66;03m# Test the watermarking pipeline\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[10], line 188\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    185\u001b[0m attacked_image \u001b[38;5;241m=\u001b[39m apply_attacks(watermarked_image, attack_type, param)\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# Extract watermark from attacked image\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m extracted_watermark \u001b[38;5;241m=\u001b[39m \u001b[43mextract_watermark\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattacked_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;66;03m# Calculate BER\u001b[39;00m\n\u001b[0;32m    191\u001b[0m ber \u001b[38;5;241m=\u001b[39m calculate_ber(watermark, extracted_watermark)\n",
      "Cell \u001b[1;32mIn[8], line 107\u001b[0m, in \u001b[0;36mextract_watermark\u001b[1;34m(image, watermark_size, alpha, beta, r)\u001b[0m\n\u001b[0;32m    105\u001b[0m h, w \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    106\u001b[0m D \u001b[38;5;241m=\u001b[39m r \u001b[38;5;241m*\u001b[39m (w \u001b[38;5;241m+\u001b[39m h)\n\u001b[1;32m--> 107\u001b[0m points \u001b[38;5;241m=\u001b[39m \u001b[43mget_feature_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m selected \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m points:\n",
      "Cell \u001b[1;32mIn[8], line 25\u001b[0m, in \u001b[0;36mget_feature_points\u001b[1;34m(image, num_octaves, th)\u001b[0m\n\u001b[0;32m     23\u001b[0m coords \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnonzero(local_max \u001b[38;5;241m&\u001b[39m (r \u001b[38;5;241m>\u001b[39m th))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m y, x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mcoords):\n\u001b[1;32m---> 25\u001b[0m     lap \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mabs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgaussian_laplace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_image\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[y, x] \u001b[38;5;241m*\u001b[39m sigma\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     26\u001b[0m     lap_prev \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(gaussian_laplace(current_image, sigma \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1.2\u001b[39m))[y, x] \u001b[38;5;241m*\u001b[39m (sigma \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m1.2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sigma \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.6\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     27\u001b[0m     lap_next \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mabs(gaussian_laplace(current_image, sigma \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.2\u001b[39m))[y, x] \u001b[38;5;241m*\u001b[39m (sigma \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1.2\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy.ndimage import zoom, rotate\n",
    "from skimage import filters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import your watermarking functions (assuming they're in a file called watermark.py)\n",
    "# from watermark import embed_watermark, extract_watermark\n",
    "\n",
    "def load_and_preprocess_images(host_path, watermark_path):\n",
    "    \"\"\"\n",
    "    Load and preprocess host and watermark images\n",
    "    \"\"\"\n",
    "    # Load host image and convert to grayscale\n",
    "    host_image = cv2.imread(host_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if host_image is None:\n",
    "        raise ValueError(f\"Could not load host image from {host_path}\")\n",
    "    \n",
    "    # Load watermark image\n",
    "    watermark_img = cv2.imread(watermark_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if watermark_img is None:\n",
    "        raise ValueError(f\"Could not load watermark image from {watermark_path}\")\n",
    "    \n",
    "    # Resize watermark to 32x32\n",
    "    watermark_resized = cv2.resize(watermark_img, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Convert watermark to binary using Otsu's thresholding\n",
    "    threshold_value = filters.threshold_otsu(watermark_resized)\n",
    "    watermark_binary = (watermark_resized > threshold_value).astype(np.float32)\n",
    "    \n",
    "    # Convert to +1/-1 format for watermarking\n",
    "    watermark_binary = 2 * watermark_binary - 1\n",
    "    \n",
    "    return host_image, watermark_binary\n",
    "\n",
    "def calculate_psnr(original, processed):\n",
    "    \"\"\"\n",
    "    Calculate Peak Signal-to-Noise Ratio (PSNR) between two images\n",
    "    \"\"\"\n",
    "    mse = np.mean((original.astype(np.float64) - processed.astype(np.float64)) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')\n",
    "    \n",
    "    max_pixel = 255.0\n",
    "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "    return psnr\n",
    "\n",
    "def calculate_ber(original, extracted):\n",
    "    \"\"\"\n",
    "    Calculate Bit Error Rate (BER) between original and extracted watermarks\n",
    "    \"\"\"\n",
    "    # Convert to binary format for comparison\n",
    "    original_bin = (original > 0).astype(int)\n",
    "    extracted_bin = (extracted > 0).astype(int)\n",
    "    \n",
    "    # Calculate bit error rate\n",
    "    errors = np.sum(original_bin != extracted_bin)\n",
    "    total_bits = original_bin.size\n",
    "    ber = errors / total_bits\n",
    "    return ber\n",
    "\n",
    "def apply_attacks(image, attack_type='rotation', param=5):\n",
    "    \"\"\"\n",
    "    Apply various attacks to the watermarked image\n",
    "    \"\"\"\n",
    "    if attack_type == 'rotation':\n",
    "        # Rotate image by param degrees\n",
    "        attacked = rotate(image, param, reshape=False, mode='constant', cval=0)\n",
    "    elif attack_type == 'scaling':\n",
    "        # Scale image by param factor\n",
    "        attacked = zoom(image, param, order=1)\n",
    "        # If scaled up, crop to original size\n",
    "        if param > 1:\n",
    "            h, w = image.shape\n",
    "            start_h = (attacked.shape[0] - h) // 2\n",
    "            start_w = (attacked.shape[1] - w) // 2\n",
    "            attacked = attacked[start_h:start_h+h, start_w:start_w+w]\n",
    "        # If scaled down, pad to original size\n",
    "        elif param < 1:\n",
    "            h, w = image.shape\n",
    "            pad_h = (h - attacked.shape[0]) // 2\n",
    "            pad_w = (w - attacked.shape[1]) // 2\n",
    "            attacked = np.pad(attacked, ((pad_h, h-attacked.shape[0]-pad_h), \n",
    "                                       (pad_w, w-attacked.shape[1]-pad_w)), \n",
    "                            mode='constant', constant_values=0)\n",
    "    elif attack_type == 'noise':\n",
    "        # Add Gaussian noise with standard deviation param\n",
    "        noise = np.random.normal(0, param, image.shape)\n",
    "        attacked = image + noise\n",
    "        attacked = np.clip(attacked, 0, 255)\n",
    "    else:\n",
    "        attacked = image\n",
    "    \n",
    "    return attacked.astype(image.dtype)\n",
    "\n",
    "def visualize_results(host, watermark, watermarked, attacked, extracted):\n",
    "    \"\"\"\n",
    "    Visualize the watermarking process and results\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    \n",
    "    # Original host image\n",
    "    axes[0, 0].imshow(host, cmap='gray')\n",
    "    axes[0, 0].set_title('Host Image')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Original watermark\n",
    "    axes[0, 1].imshow(watermark, cmap='gray')\n",
    "    axes[0, 1].set_title('Original Watermark')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Watermarked image\n",
    "    axes[0, 2].imshow(watermarked, cmap='gray')\n",
    "    axes[0, 2].set_title('Watermarked Image')\n",
    "    axes[0, 2].axis('off')\n",
    "    \n",
    "    # Attacked image\n",
    "    axes[1, 0].imshow(attacked, cmap='gray')\n",
    "    axes[1, 0].set_title('Attacked Image')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Extracted watermark\n",
    "    axes[1, 1].imshow(extracted, cmap='gray')\n",
    "    axes[1, 1].set_title('Extracted Watermark')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Difference between original and extracted\n",
    "    diff = np.abs(watermark - extracted)\n",
    "    axes[1, 2].imshow(diff, cmap='hot')\n",
    "    axes[1, 2].set_title('Difference (Original vs Extracted)')\n",
    "    axes[1, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function demonstrating the complete watermarking pipeline\n",
    "    \"\"\"\n",
    "    # File paths (replace with your actual image paths)\n",
    "    host_path = 'images/s.jpg'\n",
    "    watermark_path = 'images/cat-wm.jpg'\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess images\n",
    "        print(\"Loading and preprocessing images...\")\n",
    "        host_image, watermark = load_and_preprocess_images(host_path, watermark_path)\n",
    "        print(f\"Host image shape: {host_image.shape}\")\n",
    "        print(f\"Watermark shape: {watermark.shape}\")\n",
    "        \n",
    "        # Embed watermark\n",
    "        print(\"\\nEmbedding watermark...\")\n",
    "        watermarked_image = embed_watermark(host_image, watermark, alpha=0.2, beta=0.05, r=0.01)\n",
    "        \n",
    "        # Calculate PSNR between host and watermarked image\n",
    "        psnr_value = calculate_psnr(host_image, watermarked_image)\n",
    "        print(f\"PSNR (Host vs Watermarked): {psnr_value:.2f} dB\")\n",
    "        \n",
    "        # Test without attacks (baseline)\n",
    "        print(\"\\nTesting extraction without attacks...\")\n",
    "        extracted_clean = extract_watermark(watermarked_image)\n",
    "        ber_clean = calculate_ber(watermark, extracted_clean)\n",
    "        print(f\"BER (No attack): {ber_clean:.4f} ({ber_clean*100:.2f}%)\")\n",
    "        \n",
    "        # Attack simulations\n",
    "        attacks_to_test = [\n",
    "            ('rotation', 5, 'Rotation 5°'),\n",
    "            ('rotation', 10, 'Rotation 10°'),\n",
    "            ('rotation', -5, 'Rotation -5°'),\n",
    "            ('scaling', 0.8, 'Scaling 0.8x'),\n",
    "            ('scaling', 1.2, 'Scaling 1.2x'),\n",
    "            ('scaling', 0.9, 'Scaling 0.9x'),\n",
    "            ('noise', 5, 'Gaussian Noise σ=5'),\n",
    "            ('noise', 10, 'Gaussian Noise σ=10'),\n",
    "        ]\n",
    "        \n",
    "        print(\"\\nTesting robustness against attacks:\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        attack_results = []\n",
    "        \n",
    "        for attack_type, param, description in attacks_to_test:\n",
    "            # Apply attack\n",
    "            attacked_image = apply_attacks(watermarked_image, attack_type, param)\n",
    "            \n",
    "            # Extract watermark from attacked image\n",
    "            extracted_watermark = extract_watermark(attacked_image)\n",
    "            \n",
    "            # Calculate BER\n",
    "            ber = calculate_ber(watermark, extracted_watermark)\n",
    "            \n",
    "            # Calculate PSNR between watermarked and attacked image\n",
    "            psnr_attack = calculate_psnr(watermarked_image, attacked_image)\n",
    "            \n",
    "            attack_results.append((description, ber, psnr_attack))\n",
    "            print(f\"{description:20s}: BER = {ber:.4f} ({ber*100:5.2f}%), PSNR = {psnr_attack:6.2f} dB\")\n",
    "        \n",
    "        # Visualize one example (rotation attack)\n",
    "        print(\"\\nGenerating visualization for rotation attack...\")\n",
    "        attacked_example = apply_attacks(watermarked_image, 'rotation', 5)\n",
    "        extracted_example = extract_watermark(attacked_example)\n",
    "        \n",
    "        visualize_results(host_image, watermark, watermarked_image, \n",
    "                         attacked_example, extracted_example)\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(\"-\" * 30)\n",
    "        bers = [result[1] for result in attack_results]\n",
    "        print(f\"Average BER: {np.mean(bers):.4f} ({np.mean(bers)*100:.2f}%)\")\n",
    "        print(f\"Min BER: {np.min(bers):.4f} ({np.min(bers)*100:.2f}%)\")\n",
    "        print(f\"Max BER: {np.max(bers):.4f} ({np.max(bers)*100:.2f}%)\")\n",
    "        \n",
    "        # Test with multiple watermarks for statistical analysis\n",
    "        print(\"\\nTesting with random watermarks for statistical analysis...\")\n",
    "        np.random.seed(42)\n",
    "        n_tests = 10\n",
    "        ber_stats = []\n",
    "        \n",
    "        for i in range(n_tests):\n",
    "            # Generate random binary watermark\n",
    "            random_watermark = 2 * (np.random.rand(32, 32) > 0.5) - 1\n",
    "            \n",
    "            # Embed and extract\n",
    "            wm_img = embed_watermark(host_image, random_watermark)\n",
    "            attacked_img = apply_attacks(wm_img, 'rotation', 5)  # 5-degree rotation\n",
    "            extracted_wm = extract_watermark(attacked_img)\n",
    "            \n",
    "            ber = calculate_ber(random_watermark, extracted_wm)\n",
    "            ber_stats.append(ber)\n",
    "        \n",
    "        print(f\"Statistical analysis (n={n_tests}, rotation 5°):\")\n",
    "        print(f\"Mean BER: {np.mean(ber_stats):.4f} ± {np.std(ber_stats):.4f}\")\n",
    "        print(f\"Min BER: {np.min(ber_stats):.4f}\")\n",
    "        print(f\"Max BER: {np.max(ber_stats):.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        print(\"\\nNote: Make sure to:\")\n",
    "        print(\"1. Install required packages: pip install opencv-python pillow scikit-image\")\n",
    "        print(\"2. Replace 'host_image.jpg' and 'watermark.jpg' with actual file paths\")\n",
    "        print(\"3. Ensure the watermarking functions are imported correctly\")\n",
    "\n",
    "# Alternative: Generate synthetic images for testing\n",
    "def generate_test_images():\n",
    "    \"\"\"\n",
    "    Generate synthetic test images if real images are not available\n",
    "    \"\"\"\n",
    "    print(\"Generating synthetic test images...\")\n",
    "    \n",
    "    # Generate synthetic host image (256x256 with some texture)\n",
    "    np.random.seed(42)\n",
    "    host = np.random.rand(256, 256) * 100 + 100  # Base level + noise\n",
    "    \n",
    "    # Add some structure\n",
    "    x, y = np.meshgrid(np.arange(256), np.arange(256))\n",
    "    host += 50 * np.sin(x/20) * np.cos(y/30)  # Sinusoidal pattern\n",
    "    host = np.clip(host, 0, 255).astype(np.uint8)\n",
    "    \n",
    "    # Generate synthetic watermark (text-like pattern)\n",
    "    watermark = np.zeros((32, 32))\n",
    "    # Create a simple pattern\n",
    "    watermark[8:24, 8:24] = 1\n",
    "    watermark[10:22, 10:22] = 0\n",
    "    watermark[12:20, 12:20] = 1\n",
    "    watermark = 2 * watermark - 1  # Convert to +1/-1\n",
    "    \n",
    "    return host, watermark\n",
    "\n",
    "\n",
    "main()\n",
    "\n",
    "host, watermark = generate_test_images()\n",
    "\n",
    "# Test the watermarking pipeline\n",
    "watermarked = embed_watermark(host, watermark)\n",
    "psnr = calculate_psnr(host, watermarked)\n",
    "print(f\"PSNR: {psnr:.2f} dB\")\n",
    "\n",
    "# Test with rotation attack\n",
    "attacked = apply_attacks(watermarked, 'rotation', 5)\n",
    "extracted = extract_watermark(attacked)\n",
    "ber = calculate_ber(watermark, extracted)\n",
    "print(f\"BER after 5° rotation: {ber:.4f} ({ber*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5f3a1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Watermark:  [0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
      "Embedding: Found 100 suitable keypoints.\n",
      "Watermark embedded successfully into 'watermarked_lena.png'\n",
      "Image attacked (rotated and scaled) and saved as 'attacked_lena.png'\n",
      "Extraction: Found 100 suitable keypoints.\n",
      "Extracted Watermark: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Comparison:\n",
      "Correctly extracted bits: 14/32\n",
      "Bit Error Rate (BER): 56.25%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# --- Configuration Parameters ---\n",
    "PATCH_SIZE = 32  # Size of the normalized patches (e.g., 32x32)\n",
    "ALPHA = 10       # Watermark embedding strength\n",
    "NUM_KEYPOINTS_TO_USE = 100 # Use the 100 most stable keypoints\n",
    "\n",
    "def create_watermark(size, num_bits):\n",
    "    \"\"\"Generates a random binary sequence as the watermark.\"\"\"\n",
    "    return [random.randint(0, 1) for _ in range(num_bits)]\n",
    "\n",
    "def get_normalized_patch(image, kp):\n",
    "    \"\"\"\n",
    "    Extracts and normalizes a patch around a keypoint to be invariant\n",
    "    to scale and rotation.\n",
    "    \"\"\"\n",
    "    # Create a transformation matrix to deskew the patch\n",
    "    # It rotates the patch to align with the keypoint's orientation\n",
    "    # and scales it to a fixed size.\n",
    "    m = cv2.getRotationMatrix2D(\n",
    "        (kp.pt[0], kp.pt[1]),       # center\n",
    "        kp.angle,                  # angle\n",
    "        PATCH_SIZE / kp.size       # scale\n",
    "    )\n",
    "    # Adjust translation part of the matrix to center the patch\n",
    "    m[0, 2] -= (kp.pt[0] - PATCH_SIZE / 2.0)\n",
    "    m[1, 2] -= (kp.pt[1] - PATCH_SIZE / 2.0)\n",
    "\n",
    "    # Apply the affine transformation to the grayscale image\n",
    "    normalized_patch = cv2.warpAffine(\n",
    "        image, m, (PATCH_SIZE, PATCH_SIZE), flags=cv2.INTER_LINEAR\n",
    "    )\n",
    "    return normalized_patch\n",
    "\n",
    "def embed_watermark(image_path, watermark_bits):\n",
    "    \"\"\"\n",
    "    Embeds the watermark into the image using SIFT features.\n",
    "    \"\"\"\n",
    "    # 1. Read the image and convert to grayscale\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    watermarked_img = gray_img.copy().astype(np.float32)\n",
    "\n",
    "    # 2. Detect SIFT keypoints\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, _ = sift.detectAndCompute(gray_img, None)\n",
    "    \n",
    "    # Sort keypoints by response (strongest first) and select the best ones\n",
    "    keypoints = sorted(keypoints, key=lambda x: -x.response)[:NUM_KEYPOINTS_TO_USE]\n",
    "    \n",
    "    print(f\"Embedding: Found {len(keypoints)} suitable keypoints.\")\n",
    "    if len(keypoints) < len(watermark_bits):\n",
    "        raise ValueError(\"Not enough keypoints to embed the full watermark.\")\n",
    "\n",
    "    # 3. Embed one bit into each keypoint's patch\n",
    "    num_bits = len(watermark_bits)\n",
    "    for i, kp in enumerate(keypoints):\n",
    "        bit_to_embed = watermark_bits[i % num_bits] # Embed redundantly\n",
    "\n",
    "        # 4. Get the normalized patch for the keypoint\n",
    "        patch = get_normalized_patch(watermarked_img, kp)\n",
    "        \n",
    "        # 5. Apply DCT and modify coefficients\n",
    "        patch_dct = cv2.dct(patch.astype(np.float32))\n",
    "\n",
    "        # Select two mid-frequency coefficients (example coordinates)\n",
    "        c1_pos, c2_pos = (8, 9), (9, 8) \n",
    "        c1 = patch_dct[c1_pos]\n",
    "        c2 = patch_dct[c2_pos]\n",
    "\n",
    "        if bit_to_embed == 1:\n",
    "            if c1 <= c2:\n",
    "                c1 = c2 + ALPHA\n",
    "        else: # bit_to_embed == 0\n",
    "            if c2 <= c1:\n",
    "                c2 = c1 + ALPHA\n",
    "        \n",
    "        patch_dct[c1_pos] = c1\n",
    "        patch_dct[c2_pos] = c2\n",
    "\n",
    "        # 6. Apply inverse DCT\n",
    "        modified_patch = cv2.idct(patch_dct)\n",
    "\n",
    "        # 7. Invert the normalization to place the patch back\n",
    "        # This is a complex step often simplified by directly blending.\n",
    "        # For simplicity, we'll skip the perfect inverse transform and blend.\n",
    "        # A full implementation requires an inverse warp.\n",
    "        # Here, we just acknowledge the concept.\n",
    "        \n",
    "    # In a full implementation, the modified patches would be carefully placed back.\n",
    "    # For this conceptual code, we assume the modifications are small enough\n",
    "    # that the `watermarked_img` (which was modified in-place by `get_normalized_patch` if not copied)\n",
    "    # is the final product. A more robust method would be needed for a perfect reconstruction.\n",
    "    \n",
    "    # Convert back to a displayable format\n",
    "    final_watermarked_img = cv2.convertScaleAbs(watermarked_img)\n",
    "    return final_watermarked_img, keypoints\n",
    "\n",
    "\n",
    "def extract_watermark(image, original_watermark_len):\n",
    "    \"\"\"\n",
    "    Extracts the watermark from a (potentially attacked) image.\n",
    "    \"\"\"\n",
    "    # 1. Convert to grayscale\n",
    "    if len(image.shape) > 2:\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray_img = image\n",
    "\n",
    "    # 2. Detect SIFT keypoints\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, _ = sift.detectAndCompute(gray_img, None)\n",
    "    keypoints = sorted(keypoints, key=lambda x: -x.response)[:NUM_KEYPOINTS_TO_USE]\n",
    "    print(f\"Extraction: Found {len(keypoints)} suitable keypoints.\")\n",
    "\n",
    "    # 3. Extract bits from each patch\n",
    "    extracted_bits_collection = [[] for _ in range(original_watermark_len)]\n",
    "    \n",
    "    for kp in keypoints:\n",
    "        patch = get_normalized_patch(gray_img, kp)\n",
    "        patch_dct = cv2.dct(patch.astype(np.float32))\n",
    "\n",
    "        # Use the same coefficient positions\n",
    "        c1_pos, c2_pos = (8, 9), (9, 8)\n",
    "        c1 = patch_dct[c1_pos]\n",
    "        c2 = patch_dct[c2_pos]\n",
    "        \n",
    "        extracted_bit = 1 if c1 > c2 else 0\n",
    "        \n",
    "        # This part is simplified; a real system needs to match keypoints\n",
    "        # to know *which* watermark bit it corresponds to. Without that,\n",
    "        # we can use majority voting on the assumption of redundancy.\n",
    "        # Here, we'll just collect them all.\n",
    "        # For a robust system, we would match descriptors or use another locator.\n",
    "        # This example assumes the order of strongest keypoints is somewhat preserved.\n",
    "        \n",
    "        # Store extracted bit for majority voting\n",
    "        bit_index = len(extracted_bits_collection[0]) # Simplified mapping\n",
    "        if bit_index < original_watermark_len:\n",
    "             for i in range(original_watermark_len):\n",
    "                 # This is a conceptual simplification of redundant bit recovery\n",
    "                 extracted_bits_collection[i % original_watermark_len].append(extracted_bit)\n",
    "\n",
    "\n",
    "    # 4. Reconstruct watermark using majority voting\n",
    "    reconstructed_watermark = []\n",
    "    for bits_for_one_pos in extracted_bits_collection:\n",
    "        if not bits_for_one_pos:\n",
    "            # Handle case where not enough keypoints were found\n",
    "            reconstructed_watermark.append(0) \n",
    "            continue\n",
    "        vote = sum(bits_for_one_pos) / len(bits_for_one_pos)\n",
    "        reconstructed_watermark.append(1 if vote > 0.5 else 0)\n",
    "\n",
    "    return reconstructed_watermark\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- Main Execution ---\n",
    "    image_file = 'images/cat.webp'\n",
    "    \n",
    "    # Resize the image to 512x512\n",
    "    img = cv2.imread(image_file)\n",
    "    resized_img = cv2.resize(img, (512, 512))\n",
    "\n",
    "    # 1. Generate a watermark\n",
    "    watermark_length = 32\n",
    "    original_watermark = create_watermark(1, watermark_length)\n",
    "    print(f\"Original Watermark:  {original_watermark}\")\n",
    "\n",
    "    # 2. Embed the watermark\n",
    "    watermarked_image, _ = embed_watermark(image_file, original_watermark)\n",
    "    cv2.imwrite(\"watermarked_lena.png\", watermarked_image)\n",
    "    print(\"Watermark embedded successfully into 'watermarked_lena.png'\")\n",
    "\n",
    "    # 3. Simulate an attack\n",
    "    # Rotate by 30 degrees and scale by 80%\n",
    "    rows, cols = watermarked_image.shape\n",
    "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), 30, 0.8)\n",
    "    attacked_image = cv2.warpAffine(watermarked_image, M, (cols, rows))\n",
    "    cv2.imwrite(\"attacked_lena.png\", attacked_image)\n",
    "    print(\"Image attacked (rotated and scaled) and saved as 'attacked_lena.png'\")\n",
    "\n",
    "    # 4. Extract the watermark from the attacked image\n",
    "    extracted_watermark = extract_watermark(attacked_image, watermark_length)\n",
    "    print(f\"Extracted Watermark: {extracted_watermark}\")\n",
    "    \n",
    "    # 5. Compare results\n",
    "    correct_bits = sum(1 for o, e in zip(original_watermark, extracted_watermark) if o == e)\n",
    "    bit_error_rate = (watermark_length - correct_bits) / watermark_length\n",
    "    print(f\"\\nComparison:\")\n",
    "    print(f\"Correctly extracted bits: {correct_bits}/{watermark_length}\")\n",
    "    print(f\"Bit Error Rate (BER): {bit_error_rate:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76520a59",
   "metadata": {},
   "source": [
    "# Fourier–Mellin via log-polar DFT magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "338e4de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# =========================\n",
    "# Helpers\n",
    "# =========================\n",
    "def to_ycbcr(bgr):\n",
    "    ycrcb = cv2.cvtColor(bgr, cv2.COLOR_BGR2YCrCb).astype(np.float32)\n",
    "    Y, Cr, Cb = cv2.split(ycrcb)\n",
    "    return Y, Cr, Cb\n",
    "\n",
    "def from_ycbcr(Y, Cr, Cb, out_dtype=np.uint8):\n",
    "    # Make all channels the same depth before merging\n",
    "    Y  = Y.astype(np.float32)\n",
    "    Cr = Cr.astype(np.float32)\n",
    "    Cb = Cb.astype(np.float32)\n",
    "\n",
    "    ycrcb = cv2.merge([\n",
    "        np.clip(Y,  0, 255),\n",
    "        np.clip(Cr, 0, 255),\n",
    "        np.clip(Cb, 0, 255)\n",
    "    ])\n",
    "    bgr = cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2BGR)\n",
    "    return np.clip(bgr, 0, 255).astype(out_dtype)\n",
    "\n",
    "def dft_mag_phase(img):\n",
    "    # img: float32, single channel\n",
    "    dft = cv2.dft(img, flags=cv2.DFT_COMPLEX_OUTPUT)\n",
    "    dft_shift = np.fft.fftshift(dft, axes=(0, 1))\n",
    "    re, im = dft_shift[...,0], dft_shift[...,1]\n",
    "    mag = np.sqrt(re**2 + im**2) + 1e-8\n",
    "    phase = np.arctan2(im, re)\n",
    "    return mag, phase\n",
    "\n",
    "def idft_from_mag_phase(mag, phase):\n",
    "    re = mag * np.cos(phase)\n",
    "    im = mag * np.sin(phase)\n",
    "    dft_shift = np.stack([re, im], axis=-1)\n",
    "    dft = np.fft.ifftshift(dft_shift, axes=(0, 1))\n",
    "    img_back = cv2.idft(dft, flags=cv2.DFT_REAL_OUTPUT)\n",
    "    return img_back\n",
    "\n",
    "def logpolar(img, R=256, T=256):\n",
    "    # img: float32\n",
    "    h, w = img.shape[:2]\n",
    "    center = (w/2.0, h/2.0)\n",
    "    maxR = np.hypot(center[0], center[1])\n",
    "    # OpenCV warpPolar with LOG converts radius to log scale automatically\n",
    "    lp = cv2.warpPolar(img, (T, R), center, maxR,\n",
    "                       flags=cv2.WARP_POLAR_LOG + cv2.WARP_FILL_OUTLIERS)\n",
    "    return lp, center, maxR\n",
    "\n",
    "def inv_logpolar(lp, center, maxR, out_hw):\n",
    "    h, w = out_hw\n",
    "    cart = cv2.warpPolar(lp, (w, h), center, maxR,\n",
    "                         flags=cv2.WARP_POLAR_LOG + cv2.WARP_INVERSE_MAP + cv2.WARP_FILL_OUTLIERS)\n",
    "    return cart\n",
    "\n",
    "def circ_xcorr_fft(a, b):\n",
    "    # circular cross-correlation using FFT, returns shift index where a is shifted to best match b\n",
    "    A = np.fft.fft(a)\n",
    "    B = np.fft.fft(b)\n",
    "    cc = np.fft.ifft(A * np.conj(B)).real\n",
    "    return int(np.argmax(cc))\n",
    "\n",
    "def binarize_32x32(wm):\n",
    "    # Expect 32x32 grayscale/mono; output {0,1}\n",
    "    wm = cv2.resize(wm, (32, 32), interpolation=cv2.INTER_AREA)\n",
    "    if wm.dtype != np.uint8:\n",
    "        wm = np.clip(wm, 0, 255).astype(np.uint8)\n",
    "    _, bw = cv2.threshold(wm, 0, 1, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return bw.astype(np.uint8)\n",
    "\n",
    "# =========================\n",
    "# Scheme constants (public, no external input needed)\n",
    "# =========================\n",
    "R, T = 256, 256              # log-polar grid (rows=radius bins, cols=angle bins)\n",
    "RING_RADIUS = 28             # ring pilot row index (safe from DC; tune 20~40)\n",
    "RADIAL_ANGLE = 3             # radial pilot column index (very thin wedge)\n",
    "PILOT_ALPHA = 0.015          # pilot strength in log-magnitude domain\n",
    "BAND_R_MIN, BAND_R_MAX = 48, 160  # payload band (rows) ~ mid frequencies\n",
    "DELTA = 0.8                  # QIM step in log-mag units\n",
    "MOVE_RATIO = 0.7             # move tile mean partially towards quantizer center\n",
    "\n",
    "# Fixed PN sequences (public, compiled-in)\n",
    "rng = np.random.default_rng(12345)\n",
    "PN_ANG = rng.choice([-1.0, 1.0], size=T).astype(np.float32)        # ring pilot pattern across angles\n",
    "PN_RAD = rng.choice([-1.0, 1.0], size=R).astype(np.float32)        # radial pilot pattern across radius\n",
    "\n",
    "# =========================\n",
    "# Core: Embed\n",
    "# =========================\n",
    "def embed_watermark(bgr_host, wm32_mono):\n",
    "    \"\"\"\n",
    "    bgr_host: uint8 HxWx3, any rectangular size. Not resized.\n",
    "    wm32_mono: uint8 32x32 (0..255 or 0/1). We'll binarize with Otsu.\n",
    "    returns: uint8 watermarked BGR, same size as host\n",
    "    \"\"\"\n",
    "    H, W = bgr_host.shape[:2]\n",
    "    Y, Cr, Cb = to_ycbcr(bgr_host.astype(np.uint8))\n",
    "    Yf = Y.astype(np.float32)\n",
    "\n",
    "    # DFT → log-magnitude\n",
    "    mag, phase = dft_mag_phase(Yf)\n",
    "    logmag = np.log(mag + 1e-8)\n",
    "\n",
    "    # To log-polar\n",
    "    lp, center, maxR = logpolar(logmag, R=R, T=T)\n",
    "\n",
    "    # 1) Embed pilots\n",
    "    lp[RING_RADIUS, :] += PILOT_ALPHA * PN_ANG\n",
    "    col = (RADIAL_ANGLE % T)\n",
    "    lp[:, col] += PILOT_ALPHA * PN_RAD\n",
    "\n",
    "    # 2) Payload mapping (32x32 tiles inside [BAND_R_MIN, BAND_R_MAX] × full angle)\n",
    "    bits = binarize_32x32(wm32_mono).reshape(32, 32)\n",
    "    rows_band = BAND_R_MAX - BAND_R_MIN\n",
    "    assert rows_band >= 32, \"Increase R or adjust band to fit 32 radial tiles.\"\n",
    "\n",
    "    # compute tile sizes\n",
    "    tile_r = rows_band // 32\n",
    "    tile_t = T // 32\n",
    "\n",
    "    for i in range(32):\n",
    "        r0 = BAND_R_MIN + i * tile_r\n",
    "        r1 = r0 + tile_r\n",
    "        if i == 31: r1 = BAND_R_MAX  # last tile absorbs remainder\n",
    "\n",
    "        for j in range(32):\n",
    "            t0 = j * tile_t\n",
    "            t1 = t0 + tile_t if j < 31 else T\n",
    "\n",
    "            tile = lp[r0:r1, t0:t1]\n",
    "            if tile.size == 0:\n",
    "                continue\n",
    "\n",
    "            # QIM on tile mean (log-magnitude)\n",
    "            b = int(bits[i, j])\n",
    "            m = float(tile.mean())\n",
    "\n",
    "            # dithered QIM centers for bit 0/1 (±Δ/4 offset)\n",
    "            target = DELTA * np.round((m) / DELTA) + (DELTA/4 if b==1 else -DELTA/4)\n",
    "\n",
    "            # move mean partially toward target to control distortion\n",
    "            delta = (target - m) * MOVE_RATIO\n",
    "            lp[r0:r1, t0:t1] = tile + delta\n",
    "\n",
    "    # Inverse log-polar → exp → iDFT with original phase\n",
    "    mod_logmag = inv_logpolar(lp, center, maxR, out_hw=(H, W))\n",
    "    mag_new = np.exp(mod_logmag)  # undo log\n",
    "\n",
    "    Y_new = idft_from_mag_phase(mag_new, phase)\n",
    "    Y_new = np.clip(Y_new, 0, 255).astype(np.uint8)\n",
    "    return from_ycbcr(Y_new, Cr, Cb)\n",
    "\n",
    "# =========================\n",
    "# Core: Blind Extract\n",
    "# =========================\n",
    "def extract_watermark(bgr_watermarked):\n",
    "    \"\"\"\n",
    "    Blind extraction. Input: only the watermarked BGR image.\n",
    "    Output: recovered 32x32 watermark (uint8 0/255)\n",
    "    \"\"\"\n",
    "    H, W = bgr_watermarked.shape[:2]\n",
    "    Y, _, _ = to_ycbcr(bgr_watermarked.astype(np.uint8))\n",
    "    Yf = Y.astype(np.float32)\n",
    "\n",
    "    # DFT → log-magnitude → log-polar\n",
    "    mag, _ = dft_mag_phase(Yf)\n",
    "    logmag = np.log(mag + 1e-8)\n",
    "    lp, center, maxR = logpolar(logmag, R=R, T=T)\n",
    "\n",
    "    # === Resynchronization via pilots ===\n",
    "    # 1) Rotation (horizontal circular shift) from ring pilot row\n",
    "    ring_row = np.clip(RING_RADIUS, 0, R-1)\n",
    "    obs_ang = lp[ring_row, :].astype(np.float32)\n",
    "    shift_theta = circ_xcorr_fft(obs_ang, PN_ANG)\n",
    "    lp = np.roll(lp, -shift_theta, axis=1)  # undo rotation\n",
    "\n",
    "    # 2) Scale (vertical shift) from radial pilot column\n",
    "    col = (RADIAL_ANGLE % T)\n",
    "    obs_rad = lp[:, col].astype(np.float32)\n",
    "    shift_scale = circ_xcorr_fft(obs_rad, PN_RAD)\n",
    "    lp = np.roll(lp, -shift_scale, axis=0)  # undo scale\n",
    "\n",
    "    # === Read payload (QIM decision) ===\n",
    "    rows_band = BAND_R_MAX - BAND_R_MIN\n",
    "    tile_r = rows_band // 32\n",
    "    tile_t = T // 32\n",
    "\n",
    "    bits = np.zeros((32, 32), dtype=np.uint8)\n",
    "    for i in range(32):\n",
    "        r0 = BAND_R_MIN + i * tile_r\n",
    "        r1 = r0 + tile_r\n",
    "        if i == 31: r1 = BAND_R_MAX\n",
    "\n",
    "        for j in range(32):\n",
    "            t0 = j * tile_t\n",
    "            t1 = t0 + tile_t if j < 31 else T\n",
    "            tile = lp[r0:r1, t0:t1]\n",
    "            if tile.size == 0:\n",
    "                bits[i, j] = 0\n",
    "                continue\n",
    "\n",
    "            m = float(tile.mean())\n",
    "            # QIM decision: even vs odd bin (via offset sign)\n",
    "            # Compute distance to two nearest centers of 0 and 1 hypotheses\n",
    "            c0 = DELTA * np.round(m / DELTA) - DELTA/4\n",
    "            c1 = DELTA * np.round(m / DELTA) + DELTA/4\n",
    "            bits[i, j] = 1 if abs(m - c1) < abs(m - c0) else 0\n",
    "\n",
    "    # Return as 0/255 image\n",
    "    return (bits * 255).astype(np.uint8)\n",
    "\n",
    "# =========================\n",
    "# (Optional) PSNR\n",
    "# =========================\n",
    "def psnr(a, b):\n",
    "    a = a.astype(np.float64); b = b.astype(np.float64)\n",
    "    mse = np.mean((a - b)**2)\n",
    "    return 99.0 if mse < 1e-12 else 10.0 * np.log10((255.0**2) / mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "845cd65b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR: 4.13 dB\n",
      "Original watermark shape: (400, 400)\n",
      "Recovered watermark shape: (32, 32)\n"
     ]
    }
   ],
   "source": [
    "# read your files\n",
    "host = cv2.imread(\"images/cat.webp\")            # any WxH color image\n",
    "wm   = cv2.imread(\"images/cat-wm.jpg\", 0)    # 32x32 mono (or any mono; it will be binarized)\n",
    "\n",
    "wm_img = embed_watermark(host, wm)\n",
    "cv2.imwrite(\"watermarked.png\", wm_img)\n",
    "\n",
    "# BLIND extraction (needs only the watermarked image)\n",
    "recovered = extract_watermark(cv2.imread(\"watermarked.png\"))\n",
    "cv2.imwrite(\"recovered_32x32.png\", recovered)\n",
    "\n",
    "# Fix the PSNR calculation - compare host with watermarked image\n",
    "psnr_val = psnr(host, wm_img)\n",
    "print(f\"PSNR: {psnr_val:.2f} dB\")  # expect ~40dB+ for mild embedding\n",
    "\n",
    "# Display results\n",
    "print(f\"Original watermark shape: {wm.shape}\")\n",
    "print(f\"Recovered watermark shape: {recovered.shape}\")\n",
    "\n",
    "# Show the images (optional)\n",
    "cv2.imshow(\"Original Host\", host)\n",
    "cv2.imshow(\"Watermarked\", wm_img)\n",
    "cv2.imshow(\"Original Watermark\", wm)\n",
    "cv2.imshow(\"Recovered Watermark\", recovered)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea009e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
